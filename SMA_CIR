import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from scipy.optimize import minimize
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

data = "fed-funds-rate-historical-chart.csv"
df = pd.read_csv(data, skiprows=16, names=['date', 'value'])  # Skip first 16 rows because there's no data
df['date'] = pd.to_datetime(df['date'], errors='coerce')

all_dates = pd.date_range(start="1954-07-01", end="2024-11-01")
complete_df = pd.DataFrame({'date': all_dates})
merged_df = pd.merge(complete_df, df, on='date', how='left')

window_size = 7

merged_df['SMA_filled'] = merged_df['value'].fillna(merged_df['value'].rolling(window=window_size, min_periods=1).mean())
merged_df = merged_df[['date', 'SMA_filled']]

merged_df.set_index('date', inplace=True)

rates = merged_df['SMA_filled']

scaler = StandardScaler()
rates = pd.Series(scaler.fit_transform(rates.values.reshape(-1, 1)).flatten(), index=rates.index)

# CIR 
def cir_log_likelihood(params, rates, dt):
    kappa, theta, sigma = params
    n = len(rates)
    if kappa <= 0 or sigma <= 0:
        return np.inf  # Penalize invalid parameters
    log_likelihood = 0
    for i in range(1, n):
        mu = rates[i - 1] + kappa * (theta - rates[i - 1]) * dt
        variance = sigma**2 * rates[i - 1] * dt
        likelihood = -0.5 * np.log(2 * np.pi * variance) - 0.5 * ((rates[i] - mu)**2 / variance)
        log_likelihood += likelihood
    return -log_likelihood

def simulate_cir(r0, kappa, theta, sigma, n, dt):
    rates = [r0]
    for _ in range(1, n):
        dr = kappa * (theta - rates[-1]) * dt + sigma * np.sqrt(rates[-1] * dt) * np.random.normal()
        new_rate = rates[-1] + dr
        new_rate = max(new_rate, 0)
        rates.append(new_rate)
    return np.array(rates)

# Calibrate the model using the training data
initial_params = [0.1, 0.5, 0.02]
dt = 1 / 252 

train_size = 0.8
train_data, test_data = train_test_split(rates, train_size=train_size, shuffle=False)

train_data = train_data.reset_index(drop=True)
test_data = test_data.reset_index(drop=True)

result = minimize(cir_log_likelihood, initial_params, args=(train_data, dt), bounds=[(1e-6, None), (1e-6, 1), (1e-6, None)])
kappa, theta, sigma = result.x
print(f"Calibrated parameters:\nKappa: {kappa}\nTheta: {theta}\nSigma: {sigma}")

train_simulated = simulate_cir(train_data[0], kappa, theta, sigma, len(train_data), dt)
test_simulated = simulate_cir(test_data[0], kappa, theta, sigma, len(test_data), dt)

train_simulated = np.nan_to_num(train_simulated, nan=0)
test_simulated = np.nan_to_num(test_simulated, nan=0)

# Evaluate metrics for training data
train_mse = mean_squared_error(train_data, train_simulated)
train_mae = mean_absolute_error(train_data, train_simulated)
train_rmse = np.sqrt(train_mse)
train_r2 = r2_score(train_data, train_simulated)
train_error_variance = np.var(train_data - train_simulated)

# Evaluate metrics for testing data
test_mse = mean_squared_error(test_data, test_simulated)
test_mae = mean_absolute_error(test_data, test_simulated)
test_rmse = np.sqrt(test_mse)
test_r2 = r2_score(test_data, test_simulated)
test_error_variance = np.var(test_data - test_simulated)

# Print evluations
print("\nTraining Metrics:")
print(f"MSE: {train_mse}")
print(f"MAE: {train_mae}")
print(f"RMSE: {train_rmse}")
print(f"R^2: {train_r2}")
print(f"Variance of Errors: {train_error_variance}")

print("\nTesting Metrics:")
print(f"MSE: {test_mse}")
print(f"MAE: {test_mae}")
print(f"RMSE: {test_rmse}")
print(f"R^2: {test_r2}")
print(f"Variance of Errors: {test_error_variance}")

# Plot actual vs predicted points
plt.figure(figsize=(12, 6))
plt.scatter(train_data, train_data - train_simulated, label='Training Errors', alpha=0.6, color='blue')
plt.scatter(test_data, test_data - test_simulated, label='Testing Errors', alpha=0.6, color='orange')
plt.axhline(0, linestyle='--', color='red', linewidth=1)
plt.legend()
plt.xlabel('Actual Values')
plt.ylabel('Errors (Actual - Predicted)')
plt.title('Actual vs Predicted Errors (CIR Model)')
plt.show()

# Graph: Actual vs Predicted Rates on Testing Data
plt.figure(figsize=(12, 6))
plt.plot(merged_df.index[-len(test_data):], test_data, label="Actual Rates", color="blue", linewidth=2)
plt.plot(merged_df.index[-len(test_data):], test_simulated, label="Predicted Rates", color="red", linestyle="--", linewidth=2)
plt.xlabel("Date")
plt.ylabel("Interest Rate")
plt.title("Actual vs Predicted Interest Rates on Testing Data")
plt.legend(loc="best")
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()
